import streamlit as st
import pandas as pd
import pickle
import numpy as np
import openai
from retrying import retry
from PIL import Image
import urllib
import threading
import time
import requests
import json



# Retry parameters
retry_kwargs = {
    'stop_max_attempt_number': 5,  # Maximum number of retry attempts
    'wait_exponential_multiplier': 1000,  # Initial wait time between retries in milliseconds
    'wait_exponential_max': 10000,  # Maximum wait time between retries in milliseconds
}

DOMAIN = "https://openaccess.thecvf.com/"

@retry(**retry_kwargs)
def vectorize(text: str, model="text-embedding-ada-002"):
    text = text.replace("\n", " ")
    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']

def load_tag_vector():
    with open('resources/tag_vector.pickle', 'rb') as f:
        tag_vector = pickle.load(f)
    return tag_vector


def create_query_vec(query_tags, tag_vector):
    query_vector = []
    for tag in query_tags:
        query_vector.append(tag_vector[tag])
    query_vector = sum(np.array(query_vector)) / len(query_vector)
    return query_vector


def search_rows(tag_query_vector, text_query_vector, k, alpha):
    
    meta_df = pd.read_csv("data/vector/store/metas.csv")
    title_vec = np.load("data/vector/store/title_vector.npy")
    abst_vec = np.load("data/vector/store/abst_vector.npy")

    def calc_score(query_vector):
        title_score = title_vec @ query_vector
        abst_score = abst_vec @ query_vector
        return alpha * title_score + (1 - alpha) * abst_score
    
    if tag_query_vector is not None and text_query_vector is not None:
        query_vector = (tag_query_vector + text_query_vector) / 2.0
        score = calc_score(query_vector)
    
    elif tag_query_vector is not None:
        score = calc_score(tag_query_vector)
    
    elif text_query_vector is not None:
        score = calc_score(text_query_vector)
    
    else:
        raise ValueError("both query vector is None")

    top_k_indices = np.argsort(-score)[:k]
    return meta_df.iloc[top_k_indices]



def chat_completion_request(messages, functions=None, result=[], model="gpt-3.5-turbo-0613"):
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer " + openai.api_key,
    }
    json_data = {"model": model, "messages": messages}
    if functions is not None:
        json_data.update({"functions": functions})
    try:
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=json_data,
        )
        result.append(response)
    except Exception as e:
        print("Unable to generate ChatCompletion response")
        print(f"Exception: {e}")


def create_summary(placeholder, title, abst):
    prompt = """
    ä»¥ä¸‹ã®è«–æ–‡ã«ã¤ã„ã¦ä½•ãŒã™ã”ã„ã®ã‹ã€æ¬¡ã®é …ç›®ã‚’æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    (1)æ—¢å­˜ç ”ç©¶ã§ã¯ä½•ãŒã§ããªã‹ã£ãŸã®ã‹ã€‚
    (2)ã©ã®ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ãã‚Œã‚’è§£æ±ºã—ã‚ˆã†ã¨ã—ãŸã‹
    (3)çµæœã€ä½•ãŒé”æˆã§ããŸã®ã‹
    

    ã‚¿ã‚¤ãƒˆãƒ«: {title}
    ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ: {abst}
    æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    """.format(title=title, abst=abst)

    functions = [
        {
            "name": "format_output",
            "description": "ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã®ã‚µãƒãƒªãƒ¼",
            "parameters": {
                "type": "object",
                "properties": {
                    "problem_of_existing_research": {
                        "type": "string",
                        "description": "æ—¢å­˜ç ”ç©¶ã§ã¯ä½•ãŒã§ããªã‹ã£ãŸã®ã‹",
                    },
                    "how_to_solve": {
                        "type": "string",
                        "description": "ã©ã®ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ãã‚Œã‚’è§£æ±ºã—ã‚ˆã†ã¨ã—ãŸã‹",
                    },
                    "what_they_achieved": {
                        "type": "string",
                        "description": "çµæœã€ä½•ãŒé”æˆã§ããŸã®ã‹",
                    },
                },
                "required": ["problem_of_existing_research", "how_to_solve", "what_they_achieved"],
            },
        }
    ]

    placeholder.markdown("ChatGPTãŒè€ƒãˆä¸­ã§ã™...ğŸ˜•", unsafe_allow_html=True)
    #res = chat_completion_request(messages=[{"role": "user", "content": prompt}], functions=functions)
    m = [{"role": "user", "content": prompt}]
    result = []
    thread = threading.Thread(target=chat_completion_request, args=(m, functions, result))
    thread.start()
    i = 0
    faces = ["ğŸ˜•", "ğŸ˜†", "ğŸ˜´", "ğŸ˜Š", "ğŸ˜±", "ğŸ˜", "ğŸ˜"]
    while thread.is_alive():
        i += 1
        face = faces[i % len(faces)]
        placeholder.markdown(f"ChatGPTãŒè€ƒãˆä¸­ã§ã™...{face}", unsafe_allow_html=True)
        time.sleep(0.5)
    thread.join()

    if len(result) == 0:
        placeholder.markdown("ChatGPTã®çµæœå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ...ğŸ˜¢", unsafe_allow_html=True)
        return
    
    res = result[0]
    func_result = res.json()["choices"][0]["message"]["function_call"]["arguments"]
    output = json.loads(func_result)
    a1 = output["problem_of_existing_research"]
    a2 = output["how_to_solve"]
    a3 = output["what_they_achieved"]
    gen_text = f"""ä»¥ä¸‹ã®é …ç›®ã«ã¤ã„ã¦ChatGPTãŒå›ç­”ã—ã¾ã™ã€‚
    <ol>
        <li><b>æ—¢å­˜ç ”ç©¶ã§ã¯ä½•ãŒã§ããªã‹ã£ãŸã®ã‹</b></li>
        <li style="list-style:none;">{a1}</li>
        <li><b>ã©ã®ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ãã‚Œã‚’è§£æ±ºã—ã‚ˆã†ã¨ã—ãŸã‹</b></li>
        <li style="list-style:none;">{a2}</li>
        <li><b>çµæœã€ä½•ãŒé”æˆã§ããŸã®ã‹</b></li>
        <li style="list-style:none;">{a3}</li>
    </ol>"""
    render_text = f"""<div style="border: 1px rgb(128, 132, 149) solid; padding: 20px;">{gen_text}</div>"""
    placeholder.markdown(render_text, unsafe_allow_html=True)
    return gen_text



def main():

    st.set_page_config(page_title="LLMã«ã‚ˆã‚‹CVPRè«–æ–‡æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ")
    image = Image.open('top.png')

    st.image(image, caption='CVPR, June 18-23, 2023, Vancouver, Canada, [image-ref: wikipedia.org]', use_column_width=True)

    st.title('CVPR 2023, æ–‡æ›¸åŸ‹ã‚è¾¼ã¿ã‚’ç”¨ã„ãŸè«–æ–‡æ¤œç´¢')
    st.caption("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’OpenAI APIã‚’ä½¿ã£ã¦ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€ç´„2400ã®CVPR 2023ã®è«–æ–‡ã‹ã‚‰é–¢é€£ã™ã‚‹è«–æ–‡ã‚’æ¤œç´¢ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€è«–æ–‡ã®å†…å®¹ã‚’ChatGPTã«è¦ç´„ã—ã¦ã‚‚ã‚‰ã†ã“ã¨ãŒã§ãã¾ã™ã€‚")

    #st.sidebar.title('Settings')

    openai.api_key = st.session_state.token = st.secrets["OPENAI_API_KEY"]

    #if "token" not in st.session_state:
    #    st.session_state.token = ""

    #token = st.sidebar.text_input('ç ”ç©¶å†…å®¹ã‚’ChatGPTã«èãæ©Ÿèƒ½ã‚„ãƒ•ãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã‚‹æ¤œç´¢ã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã«ã¯ã€OpenAIã®APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (APIã‚­ãƒ¼ã‚’ç™»éŒ²ã—ãªãã¦ã‚‚ã‚¿ã‚°ã«ã‚ˆã‚‹æ¤œç´¢æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã™ã€‚)', type='password', value=st.session_state.token)

    #if st.sidebar.button('APIã‚­ãƒ¼ã®ç™»éŒ²'):
    #    openai.api_key = token
    #    st.session_state.token = token
    
    #if len(st.session_state.token) > 0:
    #    st.sidebar.write(f'ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ')

    if "search_clicked" not in st.session_state:
        st.session_state.search_clicked = False
    
    def clear_session():
        st.session_state.search_clicked = False
        if "summary_clicked" in st.session_state:
            st.session_state.pop("summary_clicked")
        
        if "summary" in st.session_state:
            st.session_state.pop("summary")

    tag_vector = load_tag_vector()

    api_available = len(st.session_state.token) > 0
    exp_text = "APIã‚’å…¥ã‚Œã‚‹ã¨å…¥åŠ›å¯èƒ½ã«ãªã‚Šã¾ã™" if not api_available else ""
    query_text = st.text_input(
        "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰(æ—¥æœ¬èª or è‹±èª) " + exp_text, value="",
        on_change=clear_session,
        disabled=not api_available)
    
    query_tags = st.multiselect("[ã‚ªãƒ—ã‚·ãƒ§ãƒ³] ã‚¿ã‚°ã®é¸æŠ(è¤‡æ•°é¸æŠå¯)", options=tag_vector.keys(), on_change=clear_session)


    target_options = ['ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æ¤œç´¢', 'ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã‹ã‚‰æ¤œç´¢', 'ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã‹ã‚‰æ¤œç´¢']
    target = st.radio("æ¤œç´¢æ¡ä»¶", target_options, on_change=clear_session)
    ratio = target_options.index(target) / 2.0

    num_results = st.selectbox('è¡¨ç¤ºä»¶æ•°:', (20, 50, 100, 200), index=0, on_change=clear_session)
    
    if st.button('æ¤œç´¢'):
        st.session_state.search_clicked = True

    has_get_params = False
    get_query_params = st.experimental_get_query_params()
    if len(get_query_params.get("q", "")) > 0 and st.session_state.search_clicked == False:
        query_text = get_query_params["q"][0]
        print("query_text", query_text)
        query_tags = []
        has_get_params = True

    #if st.button('Search') and len(query_tags) > 0:
    if (st.session_state.search_clicked and (len(query_tags) > 0 or len(query_text) > 0)) or has_get_params:
        st.markdown("## **æ¤œç´¢çµæœ**")

        if len(query_tags):
            tag_query_vector = create_query_vec(query_tags, tag_vector)
        else:
            tag_query_vector = None
        
        if len(query_text) > 0:
            text_query_vector = np.array(vectorize(query_text))
        else:
            text_query_vector = None
        
        results = search_rows(tag_query_vector, text_query_vector, k=num_results, alpha=ratio)
        results.fillna("", inplace=True)

        if "summary_clicked" not in st.session_state:
            st.session_state.summary_clicked = [False] * len(results)
        
        if "summary" not in st.session_state:
            st.session_state.summary = [""] * len(results)

        for i, (_, row) in enumerate(results.iterrows()):

            title = row['title']
            pdf_link = row['pdf_link']
            authors = row['authors']
            abst = row["abst"]
            st.markdown(f"### **[{title}]({DOMAIN + pdf_link})**")
            st.markdown(f"{authors}")
            st.caption(abst)

            link = f"[ã“ã®ç ”ç©¶ã¨ä¼¼ãŸè«–æ–‡ã‚’æ¢ã™](/?q={urllib.parse.quote(title)})"
            st.markdown(link, unsafe_allow_html=True)

            if st.button(
                "ã“ã®ç ”ç©¶ã®ä½•ãŒã™ã”ã„ã®ã‹ChatGPTã«èã",
                key=f"summary_{i}",
                disabled=st.session_state.token == ""):
                st.session_state.summary_clicked[i] = True

            if st.session_state.summary_clicked[i]:
                if len(st.session_state.summary[i]) == 0:
                    placeholder = st.empty()
                    gen_text = create_summary(placeholder, row['title'], row["abst"])
                    st.session_state.summary[i] = gen_text
                else:
                    print("summary exists")
                    st.markdown(st.session_state.summary[i], unsafe_allow_html=True)

            st.markdown("---")


if __name__ == "__main__":
    main()
